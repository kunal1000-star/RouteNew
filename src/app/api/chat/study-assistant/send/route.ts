// Study Assistant API - Phase 4: Study Buddy Integration\n// ====================================================\n\nimport { NextRequest, NextResponse } from 'next/server';\nimport { createClient } from '@supabase/supabase-js';\nimport type { Database } from '@/lib/database.types';\n\nfunction getDbForRequest(request: NextRequest) {\n  const authHeader = request.headers.get('authorization');\n  if (!authHeader || !authHeader.startsWith('Bearer ')) return null;\n  const token = authHeader.substring(7);\n  return createClient(\n    process.env.NEXT_PUBLIC_SUPABASE_URL!,\n    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,\n    { global: { headers: { Authorization: `Bearer ${token}` } } }\n  );\n}\n\n// Graceful AI service manager initialization\nasync function getAiServiceManagerSafely() {\n  try {\n    const { aiServiceManager } = await import('@/lib/ai/ai-service-manager-unified');\n    return { service: aiServiceManager, error: null, initialized: true } as const;\n  } catch (importError) {\n    console.warn(\n      'AI service manager not available:',\n      importError instanceof Error ? importError.message : String(importError)\n    );\n    return {\n      service: null,\n      error: importError instanceof Error ? importError.message : String(importError),\n      initialized: false,\n      reason: 'AI service manager modules not available'\n    } as const;\n  }\n}\n\n// Mock AI response for fallback\nfunction createMockAiResponse(message: string, chatType: string) {\n  return {\n    content: `I received your message: \"${message}\". I'm currently running in fallback mode as the advanced AI service is being initialized. Please try again in a moment for full AI capabilities.`,\n    model_used: 'fallback-v1',\n    provider: 'mock-service',\n    tokens_used: {\n      input: 10,\n      output: 20\n    },\n    latency_ms: 100,\n    query_type: chatType || 'study_assistant',\n    web_search_enabled: false,\n    fallback_used: true,\n    cached: false,\n    isTimeSensitive: false,\n    language: 'english' as const\n  };\n}\n\nexport async function POST(request: NextRequest) {\n  try {\n    const { conversationId, message, chatType, isPersonalQuery = false, provider: reqProvider } = await request.json();\n\n    if (!message || !chatType) {\n      return NextResponse.json(\n        { error: 'Missing required fields: message, chatType' },\n        { status: 400 }\n      );\n    }\n\n    // Derive authenticated user from Supabase JWT\n    const dbAuth = getDbForRequest(request);\n    if (!dbAuth) {\n      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });\n    }\n    const { data: authData, error: authError } = await dbAuth.auth.getUser();\n    if (authError || !authData?.user) {\n      return NextResponse.json({ error: 'Unauthorized: invalid or missing token' }, { status: 401 });\n    }\n    const userId = authData.user.id;\n\n    // Strict UUID validation (no fallback)\n    const UUID_REGEX = /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;\n    if (!UUID_REGEX.test(userId)) {\n      return NextResponse.json({ error: 'Invalid authenticated user id: must be a UUID' }, { status: 400 });\n    }\n    const effectiveUserId = userId;\n\n    // Rate limiting per-user per-provider (provider may come from body or default)\n    const provider = (reqProvider || 'openrouter') as string;\n    const { shouldAllow } = await import('@/lib/ai/rate-limit-manager');\n    const rl = await shouldAllow(effectiveUserId, provider);\n    if (!rl.allow) {\n      return NextResponse.json({ error: 'Rate limit exceeded', retryAfter: rl.retryAfter }, { status: 429 });\n    }\n\n    // If no conversationId provided, create new conversation\n    let finalConversationId = conversationId as string | null | undefined;\n    if (!finalConversationId) {\n      const db = getDbForRequest(request)!;\n      const { data: newConversation, error } = await db\n        .from('chat_conversations')\n        .insert({\n          user_id: effectiveUserId,\n          title: message.substring(0, 50) + (message.length > 50 ? '...' : ''),\n          chat_type: chatType,\n        })\n        .select()\n        .single();\n\n      if (error) {\n        throw new Error(`Failed to create conversation: ${error.message}`);\n      }\n\n      finalConversationId = newConversation.id;\n    } else {\n      // Validate ownership of provided conversationId\n      const db = getDbForRequest(request)!;\n      const { data: conv, error: convErr } = await db\n        .from('chat_conversations')\n        .select('id, user_id')\n        .eq('id', finalConversationId)\n        .single();\n      if (convErr || !conv || conv.user_id !== effectiveUserId) {\n        return NextResponse.json({ error: 'Forbidden: conversation does not belong to user' }, { status: 403 });\n      }\n    }\n\n    // Store user message\n    const db2 = getDbForRequest(request);\n    if (!db2) {\n      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });\n    }\n    const { error: userMessageError } = await db2\n      .from('chat_messages')\n      .insert({\n        conversation_id: finalConversationId,\n        role: 'user',\n        content: message,\n        context_included: isPersonalQuery\n      } as Database['public']['Tables']['chat_messages']['Insert']);\n\n    if (userMessageError) {\n      // Log but do not fail the entire request\n      console.error('User message error:', userMessageError);\n    }\n\n    // Try to get AI service manager safely\n    const { service: aiServiceManager, initialized } = await getAiServiceManagerSafely();\n\n    let aiResponse: any;\n    if (aiServiceManager && initialized) {\n      try {\n        aiResponse = await aiServiceManager.processQuery({\n          userId: effectiveUserId,\n          message,\n          conversationId: finalConversationId,\n          chatType: 'study_assistant',\n          includeAppData: isPersonalQuery\n        });\n      } catch (serviceError) {\n        console.warn('AI service error, using mock response:', serviceError);\n        aiResponse = createMockAiResponse(message, chatType);\n      }\n    } else {\n      aiResponse = createMockAiResponse(message, chatType);\n    }\n\n    // Store AI response\n    const db3 = getDbForRequest(request);\n    if (!db3) {\n      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });\n    }\n    const totalTokens = (aiResponse?.tokens_used?.input ?? 0) + (aiResponse?.tokens_used?.output ?? 0);\n    const { error: aiMessageError } = await db3\n      .from('chat_messages')\n      .insert({\n        conversation_id: finalConversationId,\n        role: 'assistant',\n        content: aiResponse.content,\n        model_used: aiResponse.model_used ?? aiResponse.model ?? 'unknown',\n        provider_used: aiResponse.provider_used ?? aiResponse.provider ?? 'unknown',\n        tokens_used: totalTokens,\n        latency_ms: aiResponse.latency_ms ?? 0,\n        context_included: isPersonalQuery\n      } as Database['public']['Tables']['chat_messages']['Insert']);\n\n    if (aiMessageError) {\n      console.error('AI message error:', aiMessageError);\n      // Don't fail the entire request if AI response storage fails\n    }\n\n    // Update conversation timestamp\n    const db4 = getDbForRequest(request);\n    if (!db4) {\n      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });\n    }\n    await db4\n      .from('chat_conversations')\n      .update({ updated_at: new Date().toISOString() } as Database['public']['Tables']['chat_conversations']['Update'])\n      .eq('id', finalConversationId);\n\n    // Normalize AI response to expected schema\n    const normalized = {\n      content: aiResponse.content,\n      model_used: aiResponse.model_used ?? aiResponse.model ?? 'unknown',\n      provider_used: aiResponse.provider_used ?? aiResponse.provider ?? 'unknown',\n      tokens_used: aiResponse.tokens_used ?? { input: 0, output: 0 },\n      latency_ms: aiResponse.latency_ms ?? 0,\n      query_type: aiResponse.query_type ?? 'general',\n      web_search_enabled: aiResponse.web_search_enabled ?? false,\n      fallback_used: aiResponse.fallback_used ?? !initialized,\n      cached: aiResponse.cached ?? false,\n      isTimeSensitive: aiResponse.isTimeSensitive ?? false,\n      language: 'english' as const,\n      memory_references: [] as any[]\n    };\n\n    return NextResponse.json({\n      success: true,\n      data: {\n        response: normalized,\n        conversationId: finalConversationId,\n        timestamp: new Date().toISOString()\n      }\n    });\n\n  } catch (error) {\n    console.error('Study assistant send error:', error);\n\n    // Handle different error types with consistent formatting\n    if (error instanceof Error && error.message.includes('rate limit')) {\n      return NextResponse.json(\n        {\n          success: false,\n          error: 'Rate limit reached. Please wait before sending another message.',\n          retryAfter: 60\n        },\n        { status: 429 }\n      );\n    }\n\n    if (error instanceof Error && error.message.includes('service unavailable')) {\n      return NextResponse.json(\n        {\n          success: false,\n          error: 'AI service is temporarily unavailable. Please try again later.',\n          retryAfter: 30\n        },\n        { status: 503 }\n      );\n    }\n\n    return NextResponse.json(\n      {\n        success: false,\n        error: error instanceof Error ? error.message : 'Internal server error'\n      },\n      { status: 500 }\n    );\n  }\n}\n